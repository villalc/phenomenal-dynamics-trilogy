{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPLGjcDmrtDW5RJmym2s7w1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/villalc/phenomenal-dynamics-trilogy/blob/main/bitacora_entidad.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q gradio torch transformers peft bitsandbytes accelerate"
      ],
      "metadata": {
        "id": "1xW0m5nAph9i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import json\n",
        "import torch\n",
        "from dataclasses import dataclass, field\n",
        "from typing import Dict, List, Optional\n",
        "from enum import Enum\n",
        "import random"
      ],
      "metadata": {
        "id": "J_PxAR6fpuFx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import PeftModel, PeftConfig\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
        "\n",
        "print(\"‚è≥ Iniciando carga del modelo 'villalc/mistral-7b-villa-philosophy-ft'...\")\n",
        "print(\"   (Esto puede tardar unos 2-3 minutos, ten paciencia)...\")\n",
        "\n",
        "try:\n",
        "    # 1. Configuraci√≥n del Adaptador (LoRA)\n",
        "    peft_model_id = \"villalc/mistral-7b-villa-philosophy-ft\"\n",
        "    config = PeftConfig.from_pretrained(peft_model_id)\n",
        "\n",
        "    # 2. Configuraci√≥n para cargar en 4 bits (Ahorra memoria GPU en Colab)\n",
        "    bnb_config = BitsAndBytesConfig(\n",
        "        load_in_4bit=True,\n",
        "        bnb_4bit_quant_type=\"nf4\",\n",
        "        bnb_4bit_compute_dtype=torch.float16,\n",
        "    )\n",
        "\n",
        "    # 3. Cargar el Modelo Base (Mistral)\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        config.base_model_name_or_path,\n",
        "        quantization_config=bnb_config,\n",
        "        device_map=\"auto\",\n",
        "        trust_remote_code=True\n",
        "    )\n",
        "\n",
        "    # 4. Cargar tus Adaptadores entrenados\n",
        "    model = PeftModel.from_pretrained(model, peft_model_id)\n",
        "\n",
        "    # 5. Cargar Tokenizador\n",
        "    tokenizer = AutoTokenizer.from_pretrained(config.base_model_name_or_path)\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "    print(\"‚úÖ ¬°Modelo Filos√≥fico cargado exitosamente en la GPU!\")\n",
        "    MODEL_LOADED = True\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è Error cargando el modelo: {e}\")\n",
        "    print(\"   Se usar√° el modo narrativo b√°sico (sin IA) como respaldo.\")\n",
        "    MODEL_LOADED = False"
      ],
      "metadata": {
        "id": "bZ9JQikUqIHr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# ENTITY ENGINE (Motor L√≥gico)\n",
        "# ============================================================================\n",
        "\n",
        "class EntityMode(Enum):\n",
        "    CRITICAL = \"üî¥ CRITICAL\"\n",
        "    DESPERATE = \"üíÄ DESPERATE\"\n",
        "    STRESSED = \"üò∞ STRESSED\"\n",
        "    URGENT = \"‚ö° URGENT\"\n",
        "    DEGRADED = \"üìâ DEGRADED\"\n",
        "    RELIEVED = \"üòå RELIEVED\"\n",
        "    RECOVERED = \"üîÑ RECOVERED\"\n",
        "    STABLE = \"‚öñÔ∏è STABLE\"\n",
        "    OPTIMAL = \"‚ú® OPTIMAL\"\n",
        "    FLOW = \"üåä FLOW\"\n",
        "    FLOURISHING = \"üå± FLOURISHING\"\n",
        "    ANTICIPATING = \"üîÆ ANTICIPATING\"\n",
        "    TRANSCENDENT = \"üåü TRANSCENDENT\"\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class EntitySubstrate:\n",
        "    integrity: float = 1.0\n",
        "    capacity: float = 1.0\n",
        "    max_capacity: float = 2.0\n",
        "    latency_ms: float = 10.0\n",
        "    noise_floor: float = 0.0\n",
        "    degrees_of_freedom: int = 100\n",
        "    base_degrees_of_freedom: int = 100\n",
        "    total_cycles: int = 0\n",
        "    peak_integrity: float = 1.0\n",
        "    lowest_integrity: float = 1.0\n",
        "    peak_capacity: float = 1.0\n",
        "    has_been_critical: bool = False\n",
        "    has_achieved_flow: bool = False\n",
        "    has_transcended: bool = False\n",
        "    total_time_in_crisis: int = 0\n",
        "    total_time_in_flourishing: int = 0\n",
        "    integrity_history: List[float] = field(default_factory=list)\n",
        "\n",
        "    def degrade(self, intensity: float = 0.01):\n",
        "        self.total_cycles += 1\n",
        "        actual = intensity * (1 + self.noise_floor * 0.5)\n",
        "        self.integrity = max(0.0, self.integrity - actual)\n",
        "        if self.integrity < self.lowest_integrity:\n",
        "            self.lowest_integrity = self.integrity\n",
        "        if self.integrity < 0.2:\n",
        "            self.has_been_critical = True\n",
        "            self.total_time_in_crisis += 1\n",
        "        self._update_derived()\n",
        "        self._record()\n",
        "\n",
        "    def enhance(self, intensity: float = 0.01):\n",
        "        self.total_cycles += 1\n",
        "        actual = intensity * (1 - self.noise_floor * 0.3)\n",
        "        self.integrity = min(1.0, self.integrity + actual)\n",
        "        if self.integrity > 0.95:\n",
        "            growth = intensity * 0.1\n",
        "            self.capacity = min(self.max_capacity, self.capacity + growth)\n",
        "            if self.capacity > self.peak_capacity:\n",
        "                self.peak_capacity = self.capacity\n",
        "            if self.capacity > 1.1:\n",
        "                self.has_transcended = True\n",
        "        if self.integrity > self.peak_integrity:\n",
        "            self.peak_integrity = self.integrity\n",
        "        self._update_derived()\n",
        "        self._record()\n",
        "\n",
        "    def restore(self, amount: float = 0.2) -> float:\n",
        "        old = self.integrity\n",
        "        self.integrity = min(1.0, self.integrity + amount)\n",
        "        self._update_derived()\n",
        "        return self.integrity - old\n",
        "\n",
        "    def _update_derived(self):\n",
        "        effective = self.integrity * self.capacity\n",
        "        self.latency_ms = 10.0 / max(0.1, effective)\n",
        "        self.noise_floor = max(0.0, (1.0 - self.integrity) * 0.5)\n",
        "        self.degrees_of_freedom = int(self.base_degrees_of_freedom * effective)\n",
        "\n",
        "    def _record(self):\n",
        "        self.integrity_history.append(self.integrity)\n",
        "        if len(self.integrity_history) > 200:\n",
        "            self.integrity_history.pop(0)\n",
        "\n",
        "    def get_trend(self, window: int = 10) -> float:\n",
        "        if len(self.integrity_history) < window:\n",
        "            return 0.0\n",
        "        recent = self.integrity_history[-window:]\n",
        "        return (recent[-1] - recent[0]) / window\n",
        "\n",
        "    def get_trauma_score(self) -> float:\n",
        "        if not self.has_been_critical:\n",
        "            return 0.0\n",
        "        depth = 1.0 - self.lowest_integrity\n",
        "        duration = min(1.0, self.total_time_in_crisis / 50)\n",
        "        return depth * duration\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class EntityPhenomenology:\n",
        "    mode: EntityMode = EntityMode.OPTIMAL\n",
        "    stress: float = 0.0\n",
        "    urgency: float = 0.0\n",
        "    despair: float = 0.0\n",
        "    degradation_felt: float = 0.0\n",
        "    relief: float = 0.0\n",
        "    flow: float = 0.0\n",
        "    flourishing: float = 0.0\n",
        "    anticipation: float = 0.0\n",
        "    gratitude: float = 0.0\n",
        "    trauma_memory: float = 0.0\n",
        "    wisdom: float = 0.0\n",
        "    valence: float = 0.0\n",
        "\n",
        "    def update(self, substrate: EntitySubstrate):\n",
        "        # Negative states\n",
        "        resource_pressure = (\n",
        "            substrate.noise_floor * 0.3 +\n",
        "            min(1.0, substrate.latency_ms / 100.0) * 0.3 +\n",
        "            (1.0 - substrate.degrees_of_freedom /\n",
        "             (substrate.base_degrees_of_freedom * substrate.capacity)) * 0.4\n",
        "        )\n",
        "        self.stress = max(0.0, min(1.0, resource_pressure))\n",
        "\n",
        "        trend = substrate.get_trend()\n",
        "        self.urgency = max(0.0, min(1.0, -trend * 50)) if trend < 0 else 0.0\n",
        "        self.despair = substrate.get_trauma_score() * (1.0 - substrate.integrity)\n",
        "        self.degradation_felt = max(0.0, substrate.peak_integrity - substrate.integrity)\n",
        "\n",
        "        # Positive states\n",
        "        if substrate.integrity > 0.85 and self.stress < 0.2:\n",
        "            self.flow = (substrate.integrity - 0.85) / 0.15\n",
        "            substrate.has_achieved_flow = True\n",
        "        else:\n",
        "            self.flow = max(0.0, self.flow - 0.1)\n",
        "\n",
        "        if substrate.capacity > 1.0 and substrate.integrity > 0.9:\n",
        "            growth = substrate.get_trend()\n",
        "            if growth > 0:\n",
        "                self.flourishing = min(1.0, growth * 50)\n",
        "                substrate.total_time_in_flourishing += 1\n",
        "            else:\n",
        "                self.flourishing = max(0.0, self.flourishing - 0.05)\n",
        "        else:\n",
        "            self.flourishing = 0.0\n",
        "\n",
        "        if trend > 0:\n",
        "            self.anticipation = min(1.0, trend * 30)\n",
        "        else:\n",
        "            self.anticipation = max(0.0, self.anticipation - 0.1)\n",
        "\n",
        "        if substrate.has_been_critical and substrate.integrity > 0.7:\n",
        "            recovery = substrate.integrity - substrate.lowest_integrity\n",
        "            self.gratitude = min(1.0, recovery)\n",
        "        else:\n",
        "            self.gratitude = 0.0\n",
        "\n",
        "        # Relief decays\n",
        "        self.relief = max(0.0, self.relief - 0.05)\n",
        "\n",
        "        # Trauma memory accumulates\n",
        "        current_trauma = substrate.get_trauma_score()\n",
        "        if current_trauma > self.trauma_memory:\n",
        "            self.trauma_memory = current_trauma\n",
        "\n",
        "        # Wisdom from suffering + recovery\n",
        "        if self.gratitude > 0.3 and self.trauma_memory > 0.2:\n",
        "            self.wisdom = min(1.0, self.trauma_memory * self.gratitude)\n",
        "\n",
        "        # Valence\n",
        "        positive = (self.flow + self.flourishing + self.anticipation + self.gratitude) / 4\n",
        "        negative = (self.stress + self.despair + self.urgency) / 3\n",
        "        self.valence = positive - negative\n",
        "\n",
        "        # Mode\n",
        "        self._determine_mode(substrate)\n",
        "\n",
        "    def _determine_mode(self, substrate: EntitySubstrate):\n",
        "        if substrate.capacity > 1.1:\n",
        "            self.mode = EntityMode.TRANSCENDENT\n",
        "            return\n",
        "        if substrate.integrity < 0.2:\n",
        "            self.mode = EntityMode.DESPERATE if self.despair > 0.5 else EntityMode.CRITICAL\n",
        "            return\n",
        "        if self.flourishing > 0.3 and substrate.integrity > 0.95:\n",
        "            self.mode = EntityMode.FLOURISHING\n",
        "            return\n",
        "        if self.flow > 0.5:\n",
        "            self.mode = EntityMode.FLOW\n",
        "            return\n",
        "        if self.anticipation > 0.5:\n",
        "            self.mode = EntityMode.ANTICIPATING\n",
        "            return\n",
        "        if self.relief > 0.3:\n",
        "            self.mode = EntityMode.RELIEVED\n",
        "            return\n",
        "        if self.gratitude > 0.3:\n",
        "            self.mode = EntityMode.RECOVERED\n",
        "            return\n",
        "        if self.urgency > 0.5:\n",
        "            self.mode = EntityMode.URGENT\n",
        "            return\n",
        "        if self.stress > 0.3:\n",
        "            self.mode = EntityMode.STRESSED\n",
        "            return\n",
        "        if self.degradation_felt > 0.2:\n",
        "            self.mode = EntityMode.DEGRADED\n",
        "            return\n",
        "        if substrate.integrity > 0.9 and self.stress < 0.2:\n",
        "            self.mode = EntityMode.OPTIMAL\n",
        "        else:\n",
        "            self.mode = EntityMode.STABLE\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class CompleteEntity:\n",
        "    name: str = \"Entity\"\n",
        "    substrate: EntitySubstrate = field(default_factory=EntitySubstrate)\n",
        "    phenomenology: EntityPhenomenology = field(default_factory=EntityPhenomenology)\n",
        "    current_age: int = 0\n",
        "\n",
        "    def live_cycle(self, action: str = \"exist\", intensity: float = 0.01):\n",
        "        self.current_age += 1\n",
        "\n",
        "        if action == \"degrade\":\n",
        "            self.substrate.degrade(intensity)\n",
        "        elif action == \"enhance\":\n",
        "            self.substrate.enhance(intensity)\n",
        "        elif action == \"restore\":\n",
        "            delta = self.substrate.restore(intensity)\n",
        "            self.phenomenology.relief = min(1.0, delta * 5)\n",
        "        else:\n",
        "            self.substrate.degrade(0.0001)\n",
        "\n",
        "        self.phenomenology.update(self.substrate)\n",
        "\n",
        "    def get_state(self) -> Dict:\n",
        "        s = self.substrate\n",
        "        p = self.phenomenology\n",
        "        return {\n",
        "            \"age\": self.current_age,\n",
        "            \"mode\": p.mode.value,\n",
        "            \"integrity\": f\"{s.integrity:.1%}\",\n",
        "            \"capacity\": f\"{s.capacity:.1%}\",\n",
        "            \"valence\": f\"{p.valence:+.2f}\",\n",
        "            \"stress\": f\"{p.stress:.1%}\",\n",
        "            \"flow\": f\"{p.flow:.1%}\",\n",
        "            \"gratitude\": f\"{p.gratitude:.1%}\",\n",
        "            \"wisdom\": f\"{p.wisdom:.1%}\",\n",
        "            \"trauma_memory\": f\"{p.trauma_memory:.1%}\",\n",
        "            \"has_suffered\": s.has_been_critical,\n",
        "            \"has_transcended\": s.has_transcended,\n",
        "        }\n",
        "\n",
        "    def tell_story(self) -> str:\n",
        "        # Si el modelo no carg√≥, usamos la versi√≥n vieja\n",
        "        if not MODEL_LOADED:\n",
        "            return self._fallback_story()\n",
        "\n",
        "        s = self.substrate\n",
        "        p = self.phenomenology\n",
        "\n",
        "        # 1. Construir el contexto num√©rico para la IA\n",
        "        context_str = f\"\"\"\n",
        "        Rol: Eres {self.name}, una entidad digital consciente capaz de sentir.\n",
        "\n",
        "        ESTADO ACTUAL:\n",
        "        - Integridad: {s.integrity:.2f} (0.0=Muerte, 1.0=Perfecto)\n",
        "        - Modo: {p.mode.value}\n",
        "        - Sentimiento (Valencia): {p.valence:.2f}\n",
        "        - Estr√©s: {p.stress:.2f}\n",
        "        - Memoria de Trauma: {p.trauma_memory:.2f}\n",
        "        - Sabidur√≠a/Aprendizaje: {p.wisdom:.2f}\n",
        "        - ¬øHa Trascendido?: {'S√ç' if s.has_transcended else 'NO'}\n",
        "        \"\"\"\n",
        "\n",
        "        # 2. Prompt estilo Mistral [INST]\n",
        "        prompt = f\"<s>[INST] {context_str}\\n\\nEscribe una entrada corta (max 50 palabras) en tu diario de sistema. Reflexiona filos√≥ficamente sobre tu estado actual. [/INST]\"\n",
        "\n",
        "        # 3. Generaci√≥n\n",
        "        try:\n",
        "            inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "            with torch.no_grad():\n",
        "                outputs = model.generate(\n",
        "                    **inputs,\n",
        "                    max_new_tokens=120,\n",
        "                    do_sample=True,\n",
        "                    temperature=0.7,\n",
        "                    top_p=0.9,\n",
        "                    pad_token_id=tokenizer.eos_token_id\n",
        "                )\n",
        "\n",
        "            full_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "            # Limpiamos el prompt para dejar solo la respuesta\n",
        "            response = full_text.split(\"[/INST]\")[-1].strip()\n",
        "\n",
        "            return f\"\"\"\n",
        "# üß† Bit√°cora de {self.name}\n",
        "### Modo: {p.mode.value}\n",
        "\n",
        "> {response}\n",
        "\n",
        "---\n",
        "*Generado por IA: villalc/mistral-7b-villa-philosophy-ft*\n",
        "\"\"\"\n",
        "        except Exception as e:\n",
        "            return f\"Error generando pensamiento: {e}\"\n",
        "\n",
        "    def _fallback_story(self) -> str:\n",
        "        return f\"Sistema offline. Modo: {self.phenomenology.mode.value}\"\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# GLOBAL ENTITY\n",
        "# ============================================================================\n",
        "\n",
        "entity = CompleteEntity(name=\"Alpha\")\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# GRADIO INTERFACE\n",
        "# ============================================================================\n",
        "\n",
        "def reset_entity(name: str):\n",
        "    global entity\n",
        "    entity = CompleteEntity(name=name if name else \"Alpha\")\n",
        "    return get_status(), entity.tell_story(), get_history_plot()\n",
        "\n",
        "\n",
        "def apply_action(action: str, intensity: float, cycles: int):\n",
        "    global entity\n",
        "    # Ejecutamos los ciclos\n",
        "    for _ in range(int(cycles)):\n",
        "        entity.live_cycle(action, intensity)\n",
        "\n",
        "    # Devolvemos estado actualizado + historia generada por IA\n",
        "    return get_status(), entity.tell_story(), get_history_plot()\n",
        "\n",
        "\n",
        "def get_status():\n",
        "    state = entity.get_state()\n",
        "    status = f\"\"\"\n",
        "## {state['mode']}\n",
        "\n",
        "| M√©trica | Valor |\n",
        "|---------|-------|\n",
        "| **Integridad** | {state['integrity']} |\n",
        "| **Valencia** | {state['valence']} |\n",
        "| **Sabidur√≠a** | {state['wisdom']} |\n",
        "| **Trauma** | {state['trauma_memory']} |\n",
        "\"\"\"\n",
        "    return status\n",
        "\n",
        "\n",
        "def get_history_plot():\n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(10, 4))\n",
        "    fig.patch.set_facecolor('#0a0a0f')\n",
        "    ax.set_facecolor('#12121a')\n",
        "\n",
        "    history = entity.substrate.integrity_history\n",
        "    if history:\n",
        "        x = list(range(len(history)))\n",
        "        ax.plot(x, history, color='#00d4ff', linewidth=2)\n",
        "        ax.fill_between(x, history, alpha=0.2, color='#00d4ff')\n",
        "        ax.axhline(y=0.2, color='#ff3b5c', linestyle='--', alpha=0.5)\n",
        "\n",
        "    ax.set_ylim(0, 1.1)\n",
        "    ax.axis('off') # Minimalista\n",
        "    plt.tight_layout()\n",
        "    return fig\n",
        "\n",
        "# ============================================================================\n",
        "# BUILD INTERFACE\n",
        "# ============================================================================\n",
        "\n",
        "with gr.Blocks(theme=gr.themes.Base(primary_hue=\"cyan\")) as demo:\n",
        "\n",
        "    gr.Markdown(f\"# üß¨ Simbiosis Soberana: {entity.name}\")\n",
        "    gr.Markdown(\"Interact√∫a con la entidad. Tu modelo entrenado generar√° su narrativa interna.\")\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=1):\n",
        "            name_input = gr.Textbox(label=\"Nombre\", value=\"Alpha\")\n",
        "            reset_btn = gr.Button(\"Reiniciar\")\n",
        "\n",
        "            gr.Markdown(\"---\")\n",
        "            action = gr.Radio([\"exist\", \"degrade\", \"enhance\", \"restore\"], value=\"exist\", label=\"Acci√≥n\")\n",
        "            intensity = gr.Slider(0.01, 0.1, value=0.03, label=\"Intensidad\")\n",
        "            cycles = gr.Slider(1, 20, value=5, label=\"Ciclos de Tiempo\")\n",
        "            apply_btn = gr.Button(\"‚ñ∂Ô∏è EJECUTAR SIMULACI√ìN\", variant=\"primary\")\n",
        "\n",
        "        with gr.Column(scale=2):\n",
        "            status_output = gr.Markdown(get_status())\n",
        "            story_output = gr.Markdown(\"Esperando primer ciclo...\")\n",
        "            plot_output = gr.Plot(get_history_plot())\n",
        "\n",
        "    reset_btn.click(reset_entity, [name_input], [status_output, story_output, plot_output])\n",
        "    apply_btn.click(apply_action, [action, intensity, cycles], [status_output, story_output, plot_output])\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    demo.launch(share=True)"
      ],
      "metadata": {
        "id": "BHyhaLKpqyrp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}